{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNLyliMTZl9B",
        "outputId": "b76b4469-be44-4ea0-e551-431a2881c9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.9/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=cde60205c64447e89a289c058e269aa84f824d96602e807c0d5fd72beb932528\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/34/a4/159aa12d0a510d5ff7c8f0220abbea42e5d81ecf588c4fd884\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf\n",
        "import random"
      ],
      "metadata": {
        "id": "9E_vjEI-ZnI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = SparkConf().setAppName('appName').setMaster('local[*]')"
      ],
      "metadata": {
        "id": "7K5ae-KUZnGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc=SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "g0_zixuQZnD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1\n",
        "spark = SparkSession.builder.appName(\"broadcast_join\").getOrCreate()\n",
        "\n",
        "rdd1 = spark.sparkContext.parallelize([(101, \"Taha\"), (202, \"Ali\"), (303, \"Mustafa\")]) #id,name\n",
        "rdd2 = spark.sparkContext.parallelize([(101, 19), (202, 20), (303, 40)]) #id,age\n",
        "\n",
        "broadcast_v = spark.sparkContext.broadcast(rdd1.collectAsMap())\n",
        "result = rdd2.map(lambda x: (x[0], broadcast_v.value.get(x[0]), x[1])) #id,name,age get\n",
        "result.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtJQ6VoHaQuV",
        "outputId": "57695b0b-e6c3-4a0a-cbb0-c80e26a38168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(101, 'Taha', 19), (202, 'Ali', 20), (303, 'Mustafa', 40)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2\n",
        "num=sc.accumulator(0) #55\n",
        "def f(x):\n",
        "  global num\n",
        "  num+=x\n",
        "rdd=sc.parallelize([1,2,3,4,5,6,7,8,9,10])\n",
        "rdd.foreach(f)\n",
        "final=num.value\n",
        "print(\"Accumulated value is\",final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl5F1ds8ZnBM",
        "outputId": "13639c0d-e987-4c8f-9110-bd11fa8ac3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accumulated value is 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3\n",
        "text = sc.textFile(\"text.txt\")\n",
        "\n",
        "pair = text.map(lambda line: line.split(\",\"))\n",
        "pair1=pair.map(lambda pair: (pair[0], int(pair[1])))\n",
        "high_pair = pair1.takeOrdered(5, key=lambda x: -x[1])\n",
        "\n",
        "print(\"Highest value, 5 key value pair :\")\n",
        "for pair in high_pair:\n",
        "    print(pair[0], pair[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-TM7qwkZm-d",
        "outputId": "3053f72d-37a1-4a41-f0c5-18271c70f975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highest value, 5 key value pair :\n",
            "10 30\n",
            "9 25\n",
            "6 20\n",
            "8 18\n",
            "5 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4\n",
        "scores_rdd = sc.textFile(\"score.txt\")\n",
        "\n",
        "pair_rdd = scores_rdd.map(lambda line: line.split(\",\")).map(lambda pair: (pair[1], int(pair[2])))\n",
        "top_subjects = pair_rdd.takeOrdered(5, key=lambda x: x[1])\n",
        "\n",
        "print(\"Top 5 subjects with lowest names :\")\n",
        "for subject in top_subjects:\n",
        "    print(subject[0], subject[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC4b66b8eU5G",
        "outputId": "0a0444ec-a755-47be-a79c-67baf3dc044d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 subjects with lowest names :\n",
            "Science 75\n",
            "Science 78\n",
            "Science 80\n",
            "Math 85\n",
            "English 88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5\n",
        "rdd = sc.parallelize(range(1, 21))\n",
        "sum_of_sq = rdd.filter(lambda x: x % 2 == 0).map(lambda x: x ** 2).reduce(lambda x, y: x + y)\n",
        "print(\"Sum of square of even numbers:\")\n",
        "print(sum_of_sq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOVzyOLIeZmN",
        "outputId": "20448a3c-1db2-46a0-a7ac-65a10de31ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of square of even numbers:\n",
            "1540\n"
          ]
        }
      ]
    }
  ]
}